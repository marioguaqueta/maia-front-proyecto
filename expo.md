# ğŸ¦… Proyecto de DetecciÃ³n y Conteo AutomÃ¡tico de Fauna

Este proyecto implementa un sistema de detecciÃ³n y conteo automatizado de fauna silvestre en imÃ¡genes aÃ©reas utilizando la familia de modelos **YOLO** (Ultralytics). Incluye una pipeline completa de correcciÃ³n de datos, entrenamiento con YOLO11, evaluaciÃ³n avanzada y una aplicaciÃ³n interactiva construida en **Streamlit**.

---

# ğŸ“Œ Contenido del Proyecto
- CorrecciÃ³n y estandarizaciÃ³n de anotaciones
- ConversiÃ³n de formatos (Pascal VOC â†’ YOLO)
- Entrenamiento y evaluaciÃ³n con YOLO11s
- AnÃ¡lisis de mÃ©tricas de detecciÃ³n
- AplicaciÃ³n interactiva con Streamlit
- DocumentaciÃ³n tÃ©cnica y preguntas de defensa acadÃ©mica

---

# ğŸ–¥ï¸ Â¿QuÃ© es Streamlit?

**Streamlit** es un framework de Python que permite crear **aplicaciones web interactivas** sin necesidad de conocimientos avanzados en frontend. Es ampliamente utilizado por cientÃ­ficos de datos, analistas e ingenieros de machine learning para prototipado, visualizaciÃ³n y despliegue de modelos.

### âœ”ï¸ Â¿Para quÃ© sirve?
- Dashboards interactivos
- Aplicaciones de ML/IA
- ManipulaciÃ³n de datos en tiempo real
- Interfaces amigables para pruebas de modelos

### â­ Cualidades destacadas
- Sintaxis simple (solo Python)
- Recarga automÃ¡tica al guardar cambios
- Widgets nativos (sliders, selects, botones)
- IntegraciÃ³n directa con Pandas, NumPy, Torch, TensorFlow
- Despliegue rÃ¡pido en la nube o servidores propios

---

# ğŸ¤– Â¿QuÃ© es Ultralytics?

**Ultralytics** es la organizaciÃ³n responsable de la familia de modelos YOLO. Su paquete oficial `ultralytics` provee una API simple, eficiente y rÃ¡pida para:

- Entrenar modelos
- Realizar inferencias
- Revisar mÃ©tricas y curvas
- Exportar modelos a mÃºltiples formatos

Sus modelos estÃ¡n optimizados para GPU, obteniendo un excelente equilibrio entre rapidez y precisiÃ³n.

---

# ğŸ§  Â¿QuÃ© es YOLO?

**YOLO (You Only Look Once)** es una familia de modelos *single-shot* para detecciÃ³n de objetos, conocida por ser:

- **Extremadamente rÃ¡pida**  
- **Eficiente en uso de GPU**
- **Precisa en objetos pequeÃ±os**
- **Ideal para aplicaciones en tiempo real**

### Â¿CÃ³mo funciona?
YOLO divide la imagen en una grilla y predice simultÃ¡neamente:

- LocalizaciÃ³n de cajas (bounding boxes)
- Confianza de la detecciÃ³n
- Clase del objeto

Todo en un solo paso, lo que lo hace mÃ¡s rÃ¡pido que mÃ©todos como R-CNN o Detectron2.

---

# ğŸ” ParÃ¡metros de los modelos YOLO (familia YOLO11)

Ultralytics ofrece diferentes variantes segÃºn el compromiso **velocidad/peso/precisiÃ³n**:

| Modelo | TamaÃ±o aprox | Velocidad | PrecisiÃ³n | Uso recomendado |
|--------|--------------|-----------|-----------|-----------------|
| `yolo11n` | ~4.3M params | Muy rÃ¡pida | Media | Edge devices, drones |
| `yolo11s` | ~9M params | RÃ¡pida | Alta | Uso general, producciÃ³n ligera |
| `yolo11m` | ~25M params | Media | Muy alta | Proyectos con buena GPU |
| `yolo11l` | ~43M params | Lenta | Superior | DetecciÃ³n avanzada |
| `yolo11x` | ~75M params | MÃ¡s lenta | MÃ¡xima | InvestigaciÃ³n o alta precisiÃ³n |

En este proyecto se utilizÃ³ **YOLO11s** por su excelente equilibrio entre velocidad y desempeÃ±o en objetos pequeÃ±os (crucial para fauna aÃ©rea).

---

# ğŸ“‰ Funciones de PÃ©rdida (Loss Functions) en YOLO

YOLO utiliza una combinaciÃ³n de *losses* que optimizan distintos aspectos del aprendizaje:

### **1. Bounding Box Regression Loss (bbox_loss)**
- Normalmente basada en **CIoU** o **SIoU**
- Mide quÃ© tan bien coincide la caja predicha con la real
- Considera:
  - Distancia entre centros
  - SuperposiciÃ³n (IoU)
  - RelaciÃ³n de aspecto

### **2. Classification Loss (cls_loss)**
- Basada en **Binary Cross Entropy (BCE)**  
- EvalÃºa si el modelo acierta la clase del objeto

### **3. DFL Loss (Distribution Focal Loss)**
- Introducida en YOLOv8 y mantenida en YOLO11  
- Permite una localizaciÃ³n mÃ¡s precisa mediante distribuciÃ³n de bordes

### **4. Objectness Loss**
- EvalÃºa si realmente existe un objeto dentro de la predicciÃ³n

### **Â¿Y Focal Loss?**
No se utilizÃ³ en este proyecto, pero es Ãºtil cuando hay fuerte desbalance de clases porque penaliza mÃ¡s los ejemplos difÃ­ciles.

---

# âš™ï¸ Optimizador Adam

El modelo se entrenÃ³ utilizando **Adam**, uno de los optimizadores mÃ¡s efectivos en visiÃ³n por computadora.

### Â¿QuÃ© es Adam?
Adam (Adaptive Moment Estimation) combina las ventajas de:

- **Momentum** (acumula velocidad para evitar quedar atrapado en mÃ­nimos locales)
- **RMSProp** (ajusta la tasa de aprendizaje por parÃ¡metro)

### Â¿Por quÃ© es tan efectivo?
- Utiliza tasas de aprendizaje adaptativas  
- Maneja bien gradientes ruidosos  
- Converge mÃ¡s rÃ¡pido que SGD en datasets complejos  
- Es muy estable en problemas de detecciÃ³n

### HiperparÃ¡metros comunes:
- `lr = 0.001` (tasa de aprendizaje)
- `beta1 = 0.9` (promedio mÃ³vil del gradiente)
- `beta2 = 0.999` (promedio mÃ³vil del gradiente al cuadrado)
- `eps = 1e-8` (evita divisiÃ³n por cero)

---

# â“ Preguntas y Respuestas TÃ©cnicas (FAQ)

### **1. Â¿CÃ³mo garantizaron consistencia en la correcciÃ³n de anotaciones?**
Mediante un script automatizado:
- ReindexaciÃ³n de clases (1â€“6 â†’ 0â€“5)
- ConversiÃ³n VOC â†’ YOLO
- ValidaciÃ³n de rangos y formatos  
Eliminamos variabilidad inter-anotador.

---

### **2. Â¿Por quÃ© no aplicar Focal Loss u oversampling?**
LimitaciÃ³n de tiempo.  
La correcciÃ³n de anotaciones generÃ³ el mayor impacto inmediato (+61.4% mAP).

---

### **3. Â¿Por quÃ© YOLO11s y no Detectron2 u otros modelos YOLO?**
- +3.2% mAP en objetos pequeÃ±os vs YOLOv8  
- Inferencia mÃ¡s rÃ¡pida que HerdNet  
- Eficiencia computacional ideal para despliegue

---

### **4. Â¿CÃ³mo mejorar especies poco representadas?**
- Focal Loss  
- Aumento de datos especÃ­fico  
- GANs para sÃ­ntesis  
- RecolecciÃ³n dirigida de imÃ¡genes  

---

### **5. Â¿La resoluciÃ³n reducida afecta objetos pequeÃ±os?**
SÃ­.  
Se recomienda: **pipeline multi-escala â†’ refinamiento en alta resoluciÃ³n**.

---

### **6. Â¿ValidaciÃ³n fuera de la Reserva Ennedi?**
No en esta fase.  
Se planea validar en Tanzania y SudÃ¡frica.

---

### **7. Â¿CÃ³mo evitar que el modelo aprenda el fondo?**
Aumentos de datos variados (brillo, rotaciÃ³n, mosaic).  
AÃºn asÃ­, requiere anÃ¡lisis de explicabilidad.

---

### **8. Â¿ValidaciÃ³n con biÃ³logos en campo?**
No se realizÃ³ aÃºn.  
Es un siguiente paso crÃ­tico.

---

### **9. Â¿CÃ³mo maneja oclusiones parciales?**
El modelo obtuvo 86.6% recall en manadas densas.  
Futuro: tÃ©cnicas como **repulsion loss**.

---

### **10. Â¿QuÃ© es mejor con recursos limitados: mejorar modelo o mejorar datos?**
**Mejorar los datos.**  
La correcciÃ³n de anotaciones aportÃ³ +61.4% mAP.

---

# ğŸ“‚ Estructura del Repositorio

