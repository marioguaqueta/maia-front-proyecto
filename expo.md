# ğŸ¦… Proyecto de DetecciÃ³n y Conteo AutomÃ¡tico de Fauna

Este proyecto implementa un sistema de detecciÃ³n y conteo automatizado de fauna silvestre en imÃ¡genes aÃ©reas utilizando modelos de visiÃ³n por computadora basados en la familia **YOLO** (Ultralytics). Incluye una pipeline completa de correcciÃ³n de datos, entrenamiento con YOLO11, evaluaciÃ³n y una aplicaciÃ³n interactiva construida con **Streamlit**.

---

## ğŸ“Œ Contenido del Proyecto
- CorrecciÃ³n y estandarizaciÃ³n de anotaciones
- ConversiÃ³n de formatos Pascal VOC â†’ YOLO
- Entrenamiento con YOLO11s
- EvaluaciÃ³n de desempeÃ±o
- Interfaz web interactiva con Streamlit
- DocumentaciÃ³n tÃ©cnica y preguntas frecuentes

---

# ğŸ–¥ï¸ Â¿QuÃ© es Streamlit?

**Streamlit** es un framework de Python para crear **aplicaciones web interactivas** de forma rÃ¡pida y sencilla, sin necesidad de escribir HTML, CSS ni JavaScript.

### âœ”ï¸ Â¿Para quÃ© sirve?
- Visualizar datos y grÃ¡ficos.
- Desplegar modelos de IA y ML.
- Construir dashboards interactivos.
- Crear prototipos funcionales en minutos.

### â­ Cualidades destacadas
- Sintaxis extremadamente simple (solo Python).
- Widgets integrados (sliders, selects, formularios).
- IntegraciÃ³n con Pandas, NumPy, PyTorch, TensorFlow, Matplotlib, Plotly y mÃ¡s.
- Recarga automÃ¡tica al guardar el archivo.
- Despliegue fÃ¡cil en la nube o servidores propios.

En este proyecto se utiliza para visualizar detecciones, mÃ©tricas y facilitar pruebas del modelo.

---

# ğŸ¤– Â¿QuÃ© es Ultralytics?

**Ultralytics** es la organizaciÃ³n creadora de la familia de modelos YOLO (You Only Look Once), que son los mÃ¡s utilizados en detecciÃ³n de objetos por su rapidez y precisiÃ³n.

Su paquete oficial `ultralytics` permite:
- Entrenar modelos YOLO con pocas lÃ­neas de cÃ³digo.
- Correr inferencias rÃ¡pidas.
- Revisar mÃ©tricas y grÃ¡ficas de entrenamiento.
- Exportar modelos a diferentes formatos.

### Ventajas principales
- API simple
- Modelos optimizados para GPU
- Comunidad activa y constante actualizaciÃ³n
- Ideal para problemas de visiÃ³n por computadora a gran escala

---

# ğŸ§  Uso de YOLO11

**YOLO11** es la Ãºltima versiÃ³n de los modelos YOLO, con mejoras significativas en precisiÃ³n, especialmente en objetos pequeÃ±os, y mayor eficiencia computacional.

### Â¿Por quÃ© YOLO11s?
- Excelente balance entre velocidad y precisiÃ³n.
- +3.2% mAP en objetos pequeÃ±os respecto a YOLOv8.
- Inferencia mÃ¡s rÃ¡pida que otros modelos como HerdNet.
- Ideal para despliegue en escenarios reales con hardware limitado.

YOLO11s fue la opciÃ³n mÃ¡s adecuada para detectar fauna en imÃ¡genes aÃ©reas donde los animales ocupan pocos pÃ­xeles en la escena.

---

# â“ Preguntas y Respuestas TÃ©cnicas (FAQ)

### **1. Â¿QuÃ© criterios usaron para la correcciÃ³n de anotaciones y cÃ³mo garantizaron consistencia?**
Se automatizÃ³ el proceso mediante un script en Python que:
- ReindexÃ³ las clases (de 1â€“6 â†’ 0â€“5)
- ConvirtiÃ³ coordenadas de Pascal VOC a YOLO
- ValidÃ³ rangos, formatos y coherencia  
Esto eliminÃ³ variabilidad inter-anotador y garantizÃ³ consistencia.

---

### **2. Â¿Por quÃ© no implementaron Focal Loss u oversampling para el desbalanceo de clases?**
Por limitaciones de tiempo.  
La correcciÃ³n de datos tuvo mayor impacto inmediato (+61.4% mAP), por lo que tÃ©cnicas avanzadas de balanceo se dejan como trabajo futuro.

---

### **3. Â¿Por quÃ© YOLO11s y no Detectron2 u otras variantes de YOLO?**
YOLO11s demostrÃ³:
- Mejor precisiÃ³n en objetos pequeÃ±os (+3.2% mAP vs YOLOv8)
- Mayor velocidad de inferencia
- Eficiencia para despliegue en campo  
Esto lo hizo ideal para el contexto del proyecto.

---

### **4. Â¿CÃ³mo mejorar especies poco representadas como jabalÃ­ o waterbuck?**
- Aplicar Focal Loss  
- Aumento de datos por especie  
- GeneraciÃ³n sintÃ©tica con GANs  
- RecolecciÃ³n dirigida de datos  

---

### **5. Â¿La reducciÃ³n de resoluciÃ³n afectÃ³ detecciÃ³n de individuos pequeÃ±os?**
SÃ­.  
Entrenar en 2048Ã—2048 reduce informaciÃ³n. Futuro: **pipeline multi-escala** (detecciÃ³n â†’ refinamiento en alta resoluciÃ³n).

---

### **6. Â¿Validaron generalizaciÃ³n fuera de la Reserva Ennedi?**
No en esta fase.  
Se planea validar en Tanzania y SudÃ¡frica para evaluar transferibilidad.

---

### **7. Â¿CÃ³mo evitar correlaciones espurias del fondo?**
Se aplicaron aumentos como rotaciÃ³n, brillo, mosaic.  
Aun asÃ­, se recomienda incluir explicabilidad en siguientes fases.

---

### **8. Â¿Realizaron validaciÃ³n con biÃ³logos en campo?**
No en esta etapa.  
Es un paso crÃ­tico futuro para validar utilidad real en conservaciÃ³n.

---

### **9. Â¿CÃ³mo manejan oclusiones en manadas densas?**
El modelo mostrÃ³ buen recall (86.6%).  
No se usaron tÃ©cnicas especializadas como repulsion loss, pero se consideran para iteraciones futuras.

---

### **10. Â¿QuÃ© recomiendan priorizar con recursos limitados: mejorar modelo o mejorar datos?**
**Mejorar los datos.**  
La correcciÃ³n de anotaciones aportÃ³ +61.4% mAP, superando cualquier cambio de arquitectura.

---

# ğŸ“‚ Estructura sugerida del repositorio

